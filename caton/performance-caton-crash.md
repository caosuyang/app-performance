# 性能优化-卡顿崩溃

## 主线程卡顿超阈值

1. 主线程无响应：如果主线程超过系统规定的时间无响应，就会被 Watchdog 杀掉。这时，崩溃问题对应的异常编码是 0x8badf00d。
2. 像主线程卡顿超阈值等信息，是无法通过信号捕捉到的。
3. 0x8badf00d 这种情况是出现最多的。当出现被 watchdog 杀掉的情况时，我们就可以把范围控制在主线程被卡的情况。

## 监控无法通过信号捕获的崩溃信息

1. 主线程卡顿时间超过阈值被 watchdog 杀掉这种情况，监控这类崩溃的思路和监控后台崩溃类似，我们都先要找到它们的阈值，然后在临近阈值时还在执行的后台程序，判断为将要崩溃，收集信息并上报。
2. 主线程卡顿时间超过阈值这种情况，你只要收集当前线程的堆栈信息就可以了。

注意：如何判定主线程卡顿超阈值的时机，watchdog机制使用场景，有待验证。

## 采集到崩溃信息后如何分析并解决崩溃问题呢

1. 上面解决了崩溃信息采集的问题后。现在，我们需要对这些信息进行分析，进而解决 App 的崩溃问题。
2. 采集到的崩溃日志，主要包含的信息为：进程信息、基本信息、异常信息、线程回溯。
3. 进程信息：崩溃进程的相关信息，比如崩溃报告唯一标识符、唯一键值、设备标识；
4. 基本信息：崩溃发生的日期、iOS 版本；
5. 异常信息：异常类型、异常编码、异常的线程；
6. 线程回溯：崩溃时的方法调用栈。
7. 通常情况下，我们分析崩溃日志时最先看的是异常信息，分析出问题的是哪个线程，在线程回溯里找到那个线程；然后，分析方法调用栈，符号化后的方法调用栈可以完整地看到方法调用的过程，从而知道问题发生在哪个方法的调用上。（crash符号化）
8. 方法调用栈顶，就是最后导致崩溃的方法调用。完整的崩溃日志里，除了线程方法调用栈还有异常编码。异常编码，就在异常信息里。
9. 一些被系统杀掉的情况，我们可以通过异常编码来分析。你可以在维基百科上，查看完整的异常编码。这里列出了 44 种异常编码，但常见的就是如下三种：
10. 0x8badf00d，表示 App 在一定时间内无响应而被 watchdog 杀掉的情况。
11. 0xdeadfa11，表示 App 被用户强制退出。
12. 0xc00010ff，表示 App 因为运行造成设备温度太高而被杀掉。
13. 0x8badf00d 这种情况是出现最多的。当出现被 watchdog 杀掉的情况时，我们就可以把范围控制在主线程被卡的情况。
14. 除了崩溃日志外，崩溃监控平台还需要对所有采集上来的日志进行统计。比如，腾讯的 Bugly 平台，崩溃监控平台一般都会记录信息，来辅助开发者追溯崩溃问题。
15. 有了崩溃的方法调用堆栈后，大部分问题都能够通过方法调用堆栈，来快速地定位到具体是哪个方法调用出现了问题。有些问题仅仅通过这些堆栈还无法分析出来，这时就需要借助崩溃前用户相关行为和系统环境状况的日志来进行进一步分析（埋点）。

注意：7如果方法调用栈没有符号化，需要结合ymsl进行crash堆栈符号化。15有些问题需要借助崩溃前用户相关行为和系统环境状况的日志来进行进一步分析，这块需要结合页面和事件埋点方案追踪用户行为。系统环境状况日志有待验证。

## WatchDog 机制

1. WatchDog 在不同状态下设置的不同时间，如下所示：
2. 启动（Launch）：20s；
3. 恢复（Resume）：10s；
4. 挂起（Suspend）：10s；
5. 退出（Quit）：6s；
6. 后台（Background）：3min（在 iOS 7 之前，每次申请 10min； 之后改为每次申请 3min，可连续申请，最多申请到 10min）。
7. 通过 WatchDog 设置的时间，认为可以把启动的阈值设置为 10 秒，其他状态则都默认设置为 3 秒。

注意：WatchDog 机制使用场景有待验证。

## 导致卡顿崩溃原因

1. 复杂 UI 、图文混排的绘制量过大
2. 在主线程上做网络同步请求
3. 在主线程做大量的 IO 操作
4. 运算量过大，CPU 持续高占用
5. 死锁和主子线程抢锁

## 判断卡顿阶段

1. 如果 RunLoop 的线程，进入睡眠前方法的执行时间过长而导致无法进入睡眠，或者线程唤醒后接收消息时间过长而无法进入下一步的话，就可以认为是线程受阻了。如果这个线程是主线程的话，表现出来的就是出现了卡顿。
2. 所以，如果我们要利用 RunLoop 原理来监控卡顿的话，就是要关注这两个阶段。RunLoop 在进入睡眠之前和唤醒后的两个 loop 状态定义的值，分别是 kCFRunLoopBeforeSources 和 kCFRunLoopAfterWaiting ，也就是要触发 Source0 回调和接收 mach_port 消息两个状态。

## 如何检查卡顿

1. 首先，创建一个 observerCtx 观察者
2. 将创建好的观察者添加到主线程 runloop 的 common 模式下观察
3. 然后，创建一个持续的子线程用于监控主线程的 runloop 状态 (do while)
4. 创建一个 dispatch_semphore_wait 信号量，超时时间阈值设置为 3 s，小于 watchdog 限制时间即可
5. 如果下面判断信号量大于0，那么表示信号量等待时间超过 3s，放开了锁
6. 如果 observer 正好处于 BeforeSources 或 AfterWaiting 状态
7. 即可发现进入睡眠前的 kCFRunLoopBeforeSources 状态，或者唤醒后的状态 kCFRunLoopAfterWaiting，在设置的时间阈值内一直没有变化，即可判定为卡顿
8. 接下来，我们就可以 dump 出堆栈的信息，从而进一步分析出具体是哪个方法的执行时间过长

## 如何获取卡顿的方法堆栈信息

1. 获取堆栈信息的一种方法是直接调用系统函数。
2. 另一种方法是，直接用 PLCrashReporter这个开源的第三方库来获取堆栈信息。

### 直接调用系统函数

1. 这种方法的优点在于，性能消耗小。但是，它只能够获取简单的信息，也没有办法配合 dSYM 来获取具体是哪行代码出了问题，而且能够获取的信息类型也有限。这种方法，因为性能比较好，所以适用于观察大盘统计卡顿情况，而不是想要找到卡顿原因的场景。
2. 直接调用系统函数方法的主要思路是：用 signal 进行错误信息的获取。

### PLCrashReporter获取堆栈信息

1. 这种方法的特点是，能够定位到问题代码的具体位置，而且性能消耗也不大。所以，也是推荐的获取堆栈信息的方法。
2. 具体如何使用 PLCrashReporter 来获取堆栈信息，获取数据->转换成 PLCrashReport 对象->进行字符串格式化处理->将字符串上传服务器。